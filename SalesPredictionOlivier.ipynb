{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 200px; display: inline\" alt=\"Python\"/></a> [pour Statistique et Science des Données](https://github.com/wikistat/Intro-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage Statistique / Machine avec <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 150px; display: inline\" alt=\"Python\"/></a> & <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 180px; display: inline\" alt=\"Scikit-Learn\"/></a>\n",
    "**Résumé**: Ce calepin introduit l'utilisation de la librairie `scikit-learn` pour la modélisation et l'apprentissage. Pourquoi utiliser `scikit-learn` ? Ou non ? Liste des fonctionnalités, quelques exemples de mise en oeuvre de modélisation ([régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), [$k$-plus proches voisins](http://wikistat.fr/pdf/st-m-app-add.pdf), [arbres de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf), [forêts aléatoires](http://wikistat.fr/pdf/st-m-app-agreg.pdf). Optimisation des paramètres (complexité) des modèles par [validation croisée](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf). Fontions de chaînage (*pipeline*) de transformations et estimations. D'autres fonctionalités de `Scikit-learn` sont abordées dans les calepins du [dépot sur l'apprentissage](https://github.com/wikistat/Apprentissage) statistique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "### 1.1 `Scikit-learn` *vs.*  R\n",
    "L'objectif de ce tutoriel est d'introduire l'utilisation de la librairie `scikit-learn` de Python. Seule l'utilisation directe des fonctions de modélisation sont abordées d'une manière analogue à la mise en oeuvre de R dont les librairies offrent l'accès à bien plus de méthodes. La comparaison avec R repose sur les remarques suivantes.\n",
    "\n",
    "- Cette librairie manipule des objets de classe `array` de `numpy` *chargés en mémoire* et donc de taille limitée par la RAM de l'ordinateur; de façon analogue R charge en RAM des objets de type `data.frame`.\n",
    "- `Scikit-learn` (0.18) ne reconnaît pas (ou pas encore ?) la classe `DataFrame` de `pandas`; `scikit-learn` utilise la classe `array` de `numpy`. C'est un problème pour la gestion de variables qualitatives complexes. Une variable binaire est simplement remplacée par un codage *(0,1)* mais, en présence de plusieurs modalités, traiter celles-ci comme des entiers n'a pas de sens statistique et remplacer une variable qualitative par l'ensemble des indicatrices (*dummy variables (0,1)*) de ses modalités  complique les stratégies de sélection de modèle tout en rendant inexploitable l'interprétation statistique. \n",
    "- Les implémentations en Python de certains algorithmes dans `scikit-learn` sont souvent plus efficaces et utilisent implicitement les capacités de parallélisation.\n",
    "- R offre beaucoup plus de possibilités pour la comparaison de modèles statistiques et leur interprétation. \n",
    "\n",
    "En conséquences:\n",
    "- Préférer R et ses librairies si la présentation des résultats et surtout leur interprétation (modèles) est prioritaire, si  l'utilisation et / ou la comparaison de beaucoup de méthodes est recherchée.\n",
    "- Préférer Python et `scikit-learn` pour mettre au point une chaîne de traitements (*pipe line*) opérationnelle de l'extraction à une analyse privilégiant la prévision brute à l'interprétation et pour des données quantitatives ou rendues quantitatives (\"vectorisation\" de corpus de textes).\n",
    "\n",
    "En revanche, si les données sont trop volumineuses pour la taille du disque et distribuées sur les n\\oe uds d'un *cluster* avec *Hadoop*, consulter les [calepins](https://github.com/wikistat/Ateliers-Big-Data/tree/master/1-Intro-PySpark) sur l'utilisation de *Spark*.\n",
    "\n",
    "\n",
    "### 1.2 Fonctions d'apprentissage de `Scikit-learn`\n",
    "La communauté qui développe cette librairie est très active et la fait évoluer rapidement.  Ne pas hésiter à consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) pour des compléments. Voici une sélection de ses principales fonctionnalités en lien avec la modélisation.\n",
    "\n",
    "- Transformations (standardisation, discrétisation binaire, regroupement de modalités, imputations rudimentaires de données manquantes) , \"vectorisation\" de corpus de textes (encodage, catalogue, Tf-idf), images;\n",
    "- Modéle linéaire général avec pénalisation (ridge, lasso, elastic net...), analyse discriminante linéaire et quadratique,  $k$ plus proches voisins,  processus gaussiens, classifieur bayésien naïf, arbres de régression et classification (CART), agrégation de modèles (bagging, random forest, adaboost, gradient tree boosting), perceptron multicouche (réseau de neurones), SVM (classification, régression, détection d'atypiques...);\n",
    "- Algorithmes de validation croisée (loo, k-fold, VC stratifiée...) et sélection de modèles, optimisation sur une grille de paramètres, séparation aléatoire apprentissage et test, courbe ROC;\n",
    "- Enchaînement (*pipeline*) de traitements.\n",
    "\n",
    "En résumé, cette librairie est focalisée sur les aspects \"machine\" de l'apprentissage de données quantitatives (séries, signaux, images) volumineuses tandis que R intègre l'analyse de variables qualitatives complexes et l'interprétation statistique fine des résultats au détriment parfois de l'efficacité des calculs.\n",
    "\n",
    "### 1.3 Objectif\n",
    "L'objectif est d'illustrer la mise en oeuvre de quelques fonctionnalités. Consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) et ses nombreux [exemples](http://scikit-learn.org/stable/auto_examples/index.html) pour plus de détails sur les possibilités d'utilisation de `scikit-learn`. \n",
    "\n",
    "Deux jeux de données élémentaires sont utilisés. Celui [déjà étudié](https://github.com/wikistat/Intro-Python) avec `pandas` et concernant le naufrage du Titanic. Il mélange des variables explicatives qualitatives et quantitatives dans un objet de la classe `DataFrame`. Pour être utilisé dans `scikit-learn` les données doivent être transformées en un objet de classe `Array` de `numpy` par le  remplacement des variables qualitatives par les indicatrices de leurs modalités.  L'autre ensemble de données est entièrement quantitatif. C'est un problème classique et simplifié de [reconnaissance de caractères](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits) qui est inclus dans la librairie `scikit-learn`.\n",
    "\n",
    "Après la phase d'exploration ([calepin précédent](https://github.com/wikistat/Intro-Python)), ce sont les fonctions de modélisation et apprentissage qui sont abordées: [régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf) (titanic), [$k$- plus proches voisins](http://wikistat.fr/pdf/st-m-app-add.pdf) (caractères), [arbres de discrimination](http://wikistat.fr/pdf/st-m-app-cart.pdf), et [forêts aléatoires](http://wikistat.fr/pdf/st-m-app-agreg.pdf). Les paramètres de complexité des modèles  sont optimisés par minimisation de l'[erreur de prévision](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) estimée par [validation croisée](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) *V-fold$.  \n",
    "\n",
    "D'autres fonctionnalités sont rapidement illustrées : enchaînement (*pipeline*) de méthodes et automatisation, détection d'observations atypiques. Leur maîtrise est néanmoins importante pour la mise en exploitation de codes complexes efficaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Extraction des échantillons\n",
    "Le travail préliminaire consiste à séparer les échantillons en une partie *apprentissage* et une autre de *test* pour estimer sans biais l'[erreur de prévision](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf). L'optimisation (biais-variance) de la complexité des modèles est réalisée en minimisant l'erreur estimée par [validation croisée](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) $V-fold$. \n",
    "\n",
    "### 2.1 Données \"Caractères\"\n",
    "Elles sont disponibles dans la librairie `Scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "# les données\n",
    "digits = datasets.load_digits()\n",
    "# Contenu et mode d'obtention\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(digits.images, \n",
    "   digits.target))\n",
    "for index, (image, label) in  enumerate(images_and_labels[:8]):\n",
    "     plt.subplot(2, 4, index + 1)\n",
    "     plt.axis('off')\n",
    "     plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "     plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables prédictives et cible\n",
    "X=digits.data\n",
    "y=digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Données \"Magasins\"\n",
    "\n",
    "Les données sur le naufrage du Titanic sont décrites dans le calepin consacré à la librairie *pandas*. Reconstruire la table des données en lisant le fichier .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                     object\n",
       "Day                    object\n",
       "Date                   object\n",
       "Number_of_Customers    object\n",
       "Open                   object\n",
       "Promo                  object\n",
       "State_Holiday          object\n",
       "School_Holiday         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lire les données d'apprentissage\n",
    "import pandas as pd\n",
    "path='/home/odemoly/Documents/Certificat_BD/Second_Projet/2 - public_dat/'  # si les données sont déjà dans le répertoire courant\n",
    "# path='http://www.math.univ-toulouse.fr/~besse/Wikistat/data/'\n",
    "input_string_train = open(path + 'store_train.data', 'r').read()\n",
    "df_train = pd.DataFrame([x.split(' ') for x in input_string_train.split('\\n')],columns=[\"ID\",\"Day\",\"Date\",\"Number_of_Customers\",\"Open\",\"Promo\",\"State_Holiday\",\"School_Holiday\"],\n",
    "                  dtype=int)\n",
    "                  #{\"ID\":int,\"Day\":int,\"Date\":object,\"Number_of_Customers\":int,\"Open\":int,\"Promo\":int,\"State_Holiday\":int,\"School_Holiday\":int})\n",
    "df_train.head()\n",
    "\n",
    "input_string_test = open(path + 'store_test.data', 'r').read()\n",
    "df_test = pd.DataFrame([x.split(' ') for x in input_string_test.split('\\n')],columns=[\"ID\",\"Day\",\"Date\",\"Number_of_Customers\",\"Open\",\"Promo\",\"State_Holiday\",\"School_Holiday\"],\n",
    "                  dtype=int)\n",
    "                  #{\"ID\":int,\"Day\":int,\"Date\":object,\"Number_of_Customers\":int,\"Open\":int,\"Promo\":int,\"State_Holiday\":int,\"School_Holiday\":int})\n",
    "df_test.head()\n",
    "\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Number_of_Customers</th>\n",
       "      <th>Open_Ooui</th>\n",
       "      <th>Promo_Poui</th>\n",
       "      <th>State_Holiday_StateHnon</th>\n",
       "      <th>State_Holiday_StateHc</th>\n",
       "      <th>State_Holiday_StateHa</th>\n",
       "      <th>State_Holiday_StateHb</th>\n",
       "      <th>School_Holiday_SchoolHoui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249</td>\n",
       "      <td>5</td>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850</td>\n",
       "      <td>3</td>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>776</td>\n",
       "      <td>6</td>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203439</th>\n",
       "      <td>675</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203440</th>\n",
       "      <td>930</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203441</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203442</th>\n",
       "      <td>778</td>\n",
       "      <td>3</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203443</th>\n",
       "      <td>745</td>\n",
       "      <td>6</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203444 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Day Number_of_Customers  Open_Ooui  Promo_Poui  \\\n",
       "0       249   5                 725          1           1   \n",
       "1       190   4                 564          1           0   \n",
       "2       850   3                 644          1           1   \n",
       "3       776   6                 435          1           0   \n",
       "4        14   4                 799          1           1   \n",
       "...     ...  ..                 ...        ...         ...   \n",
       "203439  675   7                   0          0           0   \n",
       "203440  930   7                   0          0           0   \n",
       "203441   37   2                 493          1           0   \n",
       "203442  778   3                 791          1           1   \n",
       "203443  745   6                 319          1           0   \n",
       "\n",
       "        State_Holiday_StateHnon  State_Holiday_StateHc  State_Holiday_StateHa  \\\n",
       "0                             1                      0                      0   \n",
       "1                             1                      0                      0   \n",
       "2                             1                      0                      0   \n",
       "3                             1                      0                      0   \n",
       "4                             1                      0                      0   \n",
       "...                         ...                    ...                    ...   \n",
       "203439                        1                      0                      0   \n",
       "203440                        1                      0                      0   \n",
       "203441                        1                      0                      0   \n",
       "203442                        1                      0                      0   \n",
       "203443                        1                      0                      0   \n",
       "\n",
       "        State_Holiday_StateHb  School_Holiday_SchoolHoui  \n",
       "0                           0                          0  \n",
       "1                           0                          0  \n",
       "2                           0                          0  \n",
       "3                           0                          0  \n",
       "4                           0                          0  \n",
       "...                       ...                        ...  \n",
       "203439                      0                          0  \n",
       "203440                      0                          0  \n",
       "203441                      0                          0  \n",
       "203442                      0                          0  \n",
       "203443                      0                          0  \n",
       "\n",
       "[203444 rows x 10 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                     category\n",
       "Day                    category\n",
       "Date                     object\n",
       "Number_of_Customers    category\n",
       "Open                   category\n",
       "Promo                  category\n",
       "State_Holiday          category\n",
       "School_Holiday         category\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape # dimensions\n",
    "# Redéfinir les types \n",
    "df_train[\"ID\"]=pd.Categorical(df_train[\"ID\"],ordered=False)\n",
    "df_train[\"Day\"]=pd.Categorical(df_train[\"Day\"],ordered=False)\n",
    "df_train[\"Open\"]=pd.Categorical(df_train[\"Open\"],ordered=False)\n",
    "df_train[\"Promo\"]=pd.Categorical(df_train[\"Promo\"],ordered=False)\n",
    "df_train[\"State_Holiday\"]=pd.Categorical(df_train[\"State_Holiday\"],ordered=False)\n",
    "df_train[\"School_Holiday\"]=pd.Categorical(df_train[\"School_Holiday\"],ordered=False)\n",
    "df_train[\"Number_of_Customers\"]=pd.Categorical(df_train[\"Number_of_Customers\"],ordered=False)\n",
    "df_train.dtypes\n",
    "\n",
    "df_test.shape # dimensions\n",
    "# Redéfinir les types \n",
    "df_test[\"ID\"]=pd.Categorical(df_test[\"ID\"],ordered=False)\n",
    "df_test[\"Day\"]=pd.Categorical(df_test[\"Day\"],ordered=False)\n",
    "df_test[\"Open\"]=pd.Categorical(df_test[\"Open\"],ordered=False)\n",
    "df_test[\"Promo\"]=pd.Categorical(df_test[\"Promo\"],ordered=False)\n",
    "df_test[\"State_Holiday\"]=pd.Categorical(df_test[\"State_Holiday\"],ordered=False)\n",
    "df_test[\"School_Holiday\"]=pd.Categorical(df_test[\"School_Holiday\"],ordered=False)\n",
    "df_test[\"Number_of_Customers\"]=pd.Categorical(df_test[\"Number_of_Customers\"],ordered=False)\n",
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = df_train[0:-1]\n",
    "df_train=new_df_train\n",
    "\n",
    "new_df_test = df_test[0:-1]\n",
    "df_test=new_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation des valeurs manquantes\n",
    "#df[\"Age\"]=df[\"Age\"].fillna(df[\"Age\"].median())\n",
    "#df.Port=df[\"Port\"].fillna(\"S\")\n",
    "df_train[\"State_Holiday\"] = df_train[\"State_Holiday\"].fillna(\"0\")\n",
    "df_train[\"School_Holiday\"] = df_train[\"School_Holiday\"].fillna(\"0\")\n",
    "df_train[\"Open\"] = df_train[\"Open\"].fillna(\"0\")\n",
    "df_train[\"Promo\"] = df_train[\"Promo\"].fillna(\"0\")\n",
    "df_train[\"Number_of_Customers\"] = df_train[\"Number_of_Customers\"].fillna(\"0\")\n",
    "df_train[\"Day\"] = df_train[\"Day\"].fillna(\"1\")\n",
    "df_train[\"ID\"] = df_train[\"ID\"].replace(to_replace=\"\",value='0')\n",
    "\n",
    "df_test[\"State_Holiday\"] = df_test[\"State_Holiday\"].fillna(\"0\")\n",
    "df_test[\"School_Holiday\"] = df_test[\"School_Holiday\"].fillna(\"0\")\n",
    "df_test[\"Open\"] = df_test[\"Open\"].fillna(\"0\")\n",
    "df_test[\"Promo\"] = df_test[\"Promo\"].fillna(\"0\")\n",
    "df_test[\"Number_of_Customers\"] = df_test[\"Number_of_Customers\"].fillna(\"0\")\n",
    "df_test[\"Day\"] = df_test[\"Day\"].fillna(\"1\")\n",
    "df_test[\"ID\"] = df_test[\"ID\"].replace(to_replace=\"\",value='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Number_of_Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>State_Holiday</th>\n",
       "      <th>School_Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-12-19</td>\n",
       "      <td>725</td>\n",
       "      <td>Ooui</td>\n",
       "      <td>Poui</td>\n",
       "      <td>StateHnon</td>\n",
       "      <td>SchoolHnon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>564</td>\n",
       "      <td>Ooui</td>\n",
       "      <td>Pnon</td>\n",
       "      <td>StateHnon</td>\n",
       "      <td>SchoolHnon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>644</td>\n",
       "      <td>Ooui</td>\n",
       "      <td>Poui</td>\n",
       "      <td>StateHnon</td>\n",
       "      <td>SchoolHnon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>776</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-03-28</td>\n",
       "      <td>435</td>\n",
       "      <td>Ooui</td>\n",
       "      <td>Pnon</td>\n",
       "      <td>StateHnon</td>\n",
       "      <td>SchoolHnon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-10-02</td>\n",
       "      <td>799</td>\n",
       "      <td>Ooui</td>\n",
       "      <td>Poui</td>\n",
       "      <td>StateHnon</td>\n",
       "      <td>SchoolHnon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Day        Date Number_of_Customers  Open Promo State_Holiday  \\\n",
       "0  249   5  2014-12-19                 725  Ooui  Poui     StateHnon   \n",
       "1  190   4  2013-02-28                 564  Ooui  Pnon     StateHnon   \n",
       "2  850   3  2013-06-05                 644  Ooui  Poui     StateHnon   \n",
       "3  776   6  2015-03-28                 435  Ooui  Pnon     StateHnon   \n",
       "4   14   4  2014-10-02                 799  Ooui  Poui     StateHnon   \n",
       "\n",
       "  School_Holiday  \n",
       "0     SchoolHnon  \n",
       "1     SchoolHnon  \n",
       "2     SchoolHnon  \n",
       "3     SchoolHnon  \n",
       "4     SchoolHnon  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discrétiser les variables quantitatives\n",
    "#df[\"AgeQ\"]=pd.qcut(df.Age,3,labels=[\"Ag1\",\"Ag2\",\"Ag3\"])\n",
    "#df[\"PrixQ\"]=pd.qcut(df.Prix,3,labels=[\"Pr1\",\"Pr2\",\"Pr3\"])\n",
    "# redéfinir les noms des modalités \n",
    "df_train[\"Open\"]=df_train[\"Open\"].cat.rename_categories([\"Onon\",\"Ooui\"])\n",
    "df_train[\"Promo\"]=df_train[\"Promo\"].cat.rename_categories([\"Pnon\",\"Poui\"])\n",
    "df_train[\"State_Holiday\"]=df_train[\"State_Holiday\"].cat.rename_categories([\"StateHnon\",\"StateHc\",\"StateHa\",\"StateHb\"])\n",
    "df_train[\"School_Holiday\"]=df_train[\"School_Holiday\"].cat.rename_categories([\"SchoolHnon\",\"SchoolHoui\"])\n",
    "df_train.head()\n",
    "\n",
    "# redéfinir les noms des modalités \n",
    "df_test[\"Open\"]=df_test[\"Open\"].cat.rename_categories([\"Onon\",\"Ooui\"])\n",
    "df_test[\"Promo\"]=df_test[\"Promo\"].cat.rename_categories([\"Pnon\",\"Poui\"])\n",
    "df_test[\"State_Holiday\"]=df_test[\"State_Holiday\"].cat.rename_categories([\"StateHnon\",\"StateHc\",\"StateHa\",\"StateHb\"])\n",
    "df_test[\"School_Holiday\"]=df_test[\"School_Holiday\"].cat.rename_categories([\"SchoolHnon\",\"SchoolHoui\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SchoolHnon', 'SchoolHoui']\n"
     ]
    }
   ],
   "source": [
    "liste = df_test[\"School_Holiday\"].values\n",
    "unique = []\n",
    "for value in liste:\n",
    "    if value not in unique:\n",
    "        unique.append(value)\n",
    "    \n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est nécessaire de transformer les données car `scikit-learn` ne reconnaît pas la classe `DataFrame` de `pandas`, ce qui est bien dommage. Les variables qualitatives sont comme précédemment remplacées par les indicatrices de leurs modalités et les variables quantitatives conservées. Cela introduit une évidente redondance dans les données mais les procédures de sélection de modèle feront le tri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table de départ\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_Onon</th>\n",
       "      <th>Open_Ooui</th>\n",
       "      <th>Promo_Pnon</th>\n",
       "      <th>Promo_Poui</th>\n",
       "      <th>State_Holiday_StateHnon</th>\n",
       "      <th>State_Holiday_StateHc</th>\n",
       "      <th>State_Holiday_StateHa</th>\n",
       "      <th>State_Holiday_StateHb</th>\n",
       "      <th>School_Holiday_SchoolHnon</th>\n",
       "      <th>School_Holiday_SchoolHoui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open_Onon  Open_Ooui  Promo_Pnon  Promo_Poui  State_Holiday_StateHnon  \\\n",
       "0          0          1           0           1                        1   \n",
       "1          0          1           1           0                        1   \n",
       "2          0          1           0           1                        1   \n",
       "3          0          1           1           0                        1   \n",
       "4          0          1           0           1                        1   \n",
       "\n",
       "   State_Holiday_StateHc  State_Holiday_StateHa  State_Holiday_StateHb  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   School_Holiday_SchoolHnon  School_Holiday_SchoolHoui  \n",
       "0                          1                          0  \n",
       "1                          1                          0  \n",
       "2                          1                          0  \n",
       "3                          1                          0  \n",
       "4                          1                          0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construction des indicatrices\n",
    "#df_q=df.drop([\"Age\",\"Prix\"],axis=1)\n",
    "#df_q.head()\n",
    "# Indicatrices\n",
    "dc_train=pd.DataFrame(pd.get_dummies(df_train[[\"Open\",\"Promo\",\"State_Holiday\",\"School_Holiday\"]]))\n",
    "dc_train.head()\n",
    "\n",
    "# Indicatrices\n",
    "dc_test=pd.DataFrame(pd.get_dummies(df_test[[\"Open\",\"Promo\",\"State_Holiday\",\"School_Holiday\"]]))\n",
    "dc_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Number_of_Customers</th>\n",
       "      <th>Open_Ooui</th>\n",
       "      <th>Promo_Poui</th>\n",
       "      <th>State_Holiday_StateHnon</th>\n",
       "      <th>State_Holiday_StateHc</th>\n",
       "      <th>State_Holiday_StateHa</th>\n",
       "      <th>State_Holiday_StateHb</th>\n",
       "      <th>School_Holiday_SchoolHoui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>3</td>\n",
       "      <td>641</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293</td>\n",
       "      <td>2</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>676</td>\n",
       "      <td>4</td>\n",
       "      <td>1584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709</td>\n",
       "      <td>3</td>\n",
       "      <td>1477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Day Number_of_Customers  Open_Ooui  Promo_Poui  \\\n",
       "0  625   3                 641          1           1   \n",
       "1  293   2                 877          1           1   \n",
       "2   39   4                 561          1           1   \n",
       "3  676   4                1584          1           1   \n",
       "4  709   3                1477          1           1   \n",
       "\n",
       "   State_Holiday_StateHnon  State_Holiday_StateHc  State_Holiday_StateHa  \\\n",
       "0                        1                      0                      0   \n",
       "1                        1                      0                      0   \n",
       "2                        1                      0                      0   \n",
       "3                        1                      0                      0   \n",
       "4                        1                      0                      0   \n",
       "\n",
       "   State_Holiday_StateHb  School_Holiday_SchoolHoui  \n",
       "0                      0                          0  \n",
       "1                      0                          1  \n",
       "2                      0                          0  \n",
       "3                      0                          0  \n",
       "4                      0                          0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table des indicatrices\n",
    "#df1=pd.get_dummies(df_q[[\"Surv\",\"Classe\",\"Genre\",\"Port\",\"AgeQ\",\"PrixQ\"]])\n",
    "# Une seule indicatrice par variable binaire\n",
    "df1_train=dc_train.drop([\"Open_Onon\",\"Promo_Pnon\",\"School_Holiday_SchoolHnon\"],axis=1)\n",
    "# Variables quantitatives\n",
    "df2_train=df_train[[\"ID\",\"Day\",\"Number_of_Customers\"]]\n",
    "# Concaténation\n",
    "df_c_train=pd.concat([df2_train,df1_train],axis=1)\n",
    "# Vérification\n",
    "df_c_train.head()\n",
    "T_train = df_c_train\n",
    "\n",
    "# Une seule indicatrice par variable binaire\n",
    "df1_test=dc_test.drop([\"Open_Onon\",\"Promo_Pnon\",\"School_Holiday_SchoolHnon\"],axis=1)\n",
    "# Variables quantitatives\n",
    "df2_test=df_test[[\"ID\",\"Day\",\"Number_of_Customers\"]]\n",
    "# Concaténation\n",
    "df_c_test=pd.concat([df2_test,df1_test],axis=1)\n",
    "# Vérification\n",
    "df_c_test.head()\n",
    "T_test = df_c_test\n",
    "\n",
    "T_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des échantillons d'apprentissage et test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Number_of_Customers</th>\n",
       "      <th>Open_Ooui</th>\n",
       "      <th>Promo_Poui</th>\n",
       "      <th>State_Holiday_StateHnon</th>\n",
       "      <th>State_Holiday_StateHc</th>\n",
       "      <th>State_Holiday_StateHa</th>\n",
       "      <th>State_Holiday_StateHb</th>\n",
       "      <th>School_Holiday_SchoolHoui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>3</td>\n",
       "      <td>641</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293</td>\n",
       "      <td>2</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>676</td>\n",
       "      <td>4</td>\n",
       "      <td>1584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709</td>\n",
       "      <td>3</td>\n",
       "      <td>1477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712040</th>\n",
       "      <td>674</td>\n",
       "      <td>6</td>\n",
       "      <td>611</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712041</th>\n",
       "      <td>1014</td>\n",
       "      <td>4</td>\n",
       "      <td>1267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712042</th>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>595</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712043</th>\n",
       "      <td>810</td>\n",
       "      <td>1</td>\n",
       "      <td>599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712044</th>\n",
       "      <td>592</td>\n",
       "      <td>1</td>\n",
       "      <td>798</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712045 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Day Number_of_Customers  Open_Ooui  Promo_Poui  \\\n",
       "0        625   3                 641          1           1   \n",
       "1        293   2                 877          1           1   \n",
       "2         39   4                 561          1           1   \n",
       "3        676   4                1584          1           1   \n",
       "4        709   3                1477          1           1   \n",
       "...      ...  ..                 ...        ...         ...   \n",
       "712040   674   6                 611          1           0   \n",
       "712041  1014   4                1267          1           1   \n",
       "712042   135   6                 595          1           0   \n",
       "712043   810   1                 599          1           1   \n",
       "712044   592   1                 798          1           1   \n",
       "\n",
       "        State_Holiday_StateHnon  State_Holiday_StateHc  State_Holiday_StateHa  \\\n",
       "0                             1                      0                      0   \n",
       "1                             1                      0                      0   \n",
       "2                             1                      0                      0   \n",
       "3                             1                      0                      0   \n",
       "4                             1                      0                      0   \n",
       "...                         ...                    ...                    ...   \n",
       "712040                        1                      0                      0   \n",
       "712041                        1                      0                      0   \n",
       "712042                        1                      0                      0   \n",
       "712043                        1                      0                      0   \n",
       "712044                        1                      0                      0   \n",
       "\n",
       "        State_Holiday_StateHb  School_Holiday_SchoolHoui  \n",
       "0                           0                          0  \n",
       "1                           0                          1  \n",
       "2                           0                          0  \n",
       "3                           0                          0  \n",
       "4                           0                          0  \n",
       "...                       ...                        ...  \n",
       "712040                      0                          0  \n",
       "712041                      0                          0  \n",
       "712042                      0                          0  \n",
       "712043                      0                          1  \n",
       "712044                      0                          0  \n",
       "\n",
       "[712045 rows x 10 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables explicatives\n",
    "#T=df_c.drop([\"Day\",\"Open_Ooui\",\"Promo_Poui\",\"State_Holiday_StateHnon\",\"State_Holiday_StateHc\",\"State_Holiday_StateHa\",\"State_Holiday_StateHb\",\"School_Holiday_SchoolHoui\"],axis=1)\n",
    "# Variable à modéliser\n",
    "#z=df_c[\"Number_of_Customers\"]\n",
    "# Extractions\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#T_train,T_test,z_train,z_test=train_test_split(T,z,test_size=0.2,random_state=11)\n",
    "T_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### solutions\n",
    "input_string_sol = open(path + 'store_train.solution', 'r').read()\n",
    "df_sol = pd.DataFrame([x.split(' ') for x in input_string_sol.split('\\n')],columns=[\"Gain\"],\n",
    "                  dtype=int)\n",
    "df_sol.head()\n",
    "z_train = df_sol[\"Gain\"]\n",
    "z_train.head()\n",
    "new_z_train = z_train[0:-1]\n",
    "z_train=new_z_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: l'échantillon test des données \"Titanic\" est relativement petit, l'estimation de l'erreur de prévision est donc sujette à caution car probablement de grande variance. Il suffit de changer l'initialisation (paramètre ` random_state`) et ré-exécuter les scripts pour s'en assurer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 *K* plus proches voisins\n",
    "Les images des caractères sont codées par des variables  quantitatives. Le problème de reconnaissance de forme ou de discrimination est adapté à l'algorithme des  [$k$-plus proches voisins](http://wikistat.fr/pdf/st-m-app-add.pdf). Le paramètre à optimiser pour contrôler la complexité du modèle est le nombre de voisin `n_neighbors`. Les autres options sont décrites dans la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-c7dde05b2d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdigit_knn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Estimation de l'erreur de prévision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# sur l'échantillon test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "digit_knn=knn.fit(X_train, y_train) \n",
    "# Estimation de l'erreur de prévision\n",
    "# sur l'échantillon test\n",
    "1-digit_knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation du paramètre de complexité du modèle par validation croisée en cherchant l'erreur minimale sur une grille de valeurs du paramètre avec `cv=5`-*fold cross validation* et `n_jobs=-1` pour une exécution en parallèle utilisant tous les processeurs sauf 1. Attention, comme la validation croisée est aléatoire, deux exécutions successives ne donnent pas le même résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# grille de valeurs\n",
    "param=[{\"n_neighbors\":list(range(1,15))}]\n",
    "knn= GridSearchCV(KNeighborsClassifier(),param,cv=5,n_jobs=-1)\n",
    "digit_knnOpt=knn.fit(X_train, y_train)\n",
    "# paramètre optimal\n",
    "digit_knnOpt.best_params_[\"n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle `digit_knnOpt` est déjà estimé avec la valeur \"optimale\" du paramètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation de l'erreur de prévision sur l'échantillon test\n",
    "1-digit_knnOpt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prévision\n",
    "y_chap = digit_knnOpt.predict(X_test)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(y_test,y_chap)\n",
    "print(table)\n",
    "plt.matshow(table)\n",
    "plt.title(\"Matrice de Confusion\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Régression logistique\n",
    "La prévision de la survie, variable binaire des données \"Titanic\", se prêtent à une [régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf). Les versions pénalisées (ridge, lasso, elastic net, lars) du modèle linéaire général sont les algorithmes les plus développés dans `Scikit-learn` au détriment de ceux plus classiques (*forward, backward, step-wise*) de sélection de variables en optimisant un critère de type AIC.  Une version lasso de la régression logistique est testée afin d'introduire la sélection automatique des variables.\n",
    "\n",
    "Estimation et erreur de prévision du modèle complet sur l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/odemoly/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/odemoly/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression()\n",
    "#print(T_train[0:-1])\n",
    "#print(z_train[0:-1])\n",
    "titan_logit=logit.fit(T_train[0:-1], z_train[0:-1])\n",
    "# Erreur sur l'écahntillon test\n",
    "#1-titan_logit.score(T_test, z_test)\n",
    "\n",
    "z_chap = titan_logit.predict(T_test[0:100])\n",
    "#z_chap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "titan_logit.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour le modèle linéaire, il faudrait construire les commandes d'aide à l'interprétation des résultats.\n",
    "\n",
    "Pénalisation et optimisation du paramètre par validation croisée. Il existe une fonction spécifique mais son mode d'emploi est peu documenté; `GridSearchCV` lui est préférée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grille de valeurs\n",
    "param=[{\"C\":[0.01,0.096,0.098,0.1,0.12,1,10]}]\n",
    "logit = GridSearchCV(LogisticRegression(penalty=\"l1\"),\n",
    "   param,cv=5,n_jobs=-1)\n",
    "titan_logitOpt=logit.fit(T_train, z_train)\n",
    "# paramètre optimal\n",
    "titan_logitOpt.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation de l'erreur de prévision par le modèle \"optimal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erreur sur l'échantillon test\n",
    "1-titan_logitOpt.score(T_test, z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petit souci supplémentaire, l'objet produit par `GridSearchCV` ne connaît pas l'attribut `.coef_`. Il faut donc ré-estimer le modèle pour connaître les coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation avec le paramètre optimal et coefficients\n",
    "LogisticRegression(penalty=\"l1\",C=titan_logitOpt.best_params_['C']).fit(T_train, z_train).coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenter : parcimonie du modèle vs. erreur de prévision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Arbre de décision\n",
    "### 4.1 Implémentation\n",
    "Les [arbres binaires de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf) (CART: *classification and regression trees*) s'appliquent à tous types de variables. Les options de l'algorithme sont décrites dans la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). La complexité du modèle est gérée par deux paramètres : `max_depth`, qui détermine le nombre max de feuilles dans l'arbre, et le nombre minimales `min_samples_split` d'observations requises pour rechercher une dichotomie. \n",
    "\n",
    "**Attention**: Même s'il s'agit d'une implémentation proche de celle originale proposée par Breiman et al. (1984) il n'existe pas (encore?) comme dans R (package `rpart`) un paramètre de pénalisation de la déviance du modèle par sa complexité (nombre de feuilles) afin de construire une séquence d'arbres emboîtés dans la perspective d'un élagage (*pruning*) optimal par validation croisée. La fonction générique de $k$-*fold cross validation* `GridSearchCV` est utilisée pour optimiser le paramètre de profondeur mais sans beaucoup de précision dans l'élagage car ce dernier élimine tout un niveau et pas les seules feuilles inutiles à la qualité de la prévision.\n",
    "\n",
    "En revanche, l'implémentation anticipe sur celles des [méthodes d'agrégation de modèles](http://wikistat.fr/pdf/st-m-app-agreg.pdf) en intégrant les paramètres (nombre de variables tirées, importance...) qui leurs sont spécifiques. D'autre part, la représentation graphique d'un arbre n'est pas incluse et nécessite l'implémentation d'un autre logiciel libre: [Graphviz](http://www.graphviz.org/). \n",
    "\n",
    "Tout ceci souligne encore les objectifs de développement de cette librairie: temps de calcul et prévision brute au détriment d'une recherche d'interprétation. Dans certains exemples éventuellement pas trop compliqués, un arbre élagué de façon optimal peut en effet prévoir à peine moins bien (différence non significative) qu'une agrégation de modèles (forêt aléatoire ou **boosting**) et apporter un éclairage nettement plus pertinent qu'un algorithme de type \"boîte noire\". \n",
    "\n",
    "## 4.2 Données \"Titanic\"\n",
    "Estimation de l'arbre complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "tree=DecisionTreeClassifier()\n",
    "digit_tree=tree.fit(T_train[0:1000], z_train[0:1000]) \n",
    "# Estimation de l'erreur de prévision\n",
    "#1-digit_tree.score(T_test,z_test)\n",
    "z_chap = digit_tree.predict(T_test)\n",
    "\n",
    "fichier = open(\"/home/odemoly/Documents/Certificat_BD/Second_Projet/submission/store_test.predict\", \"w\")\n",
    "for i in range(len(z_chap)):\n",
    "    \n",
    "    fichier.write(z_chap[i]+\"\\n\")\n",
    "    \n",
    "fichier.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Number_of_Customers</th>\n",
       "      <th>Open_Ooui</th>\n",
       "      <th>Promo_Poui</th>\n",
       "      <th>State_Holiday_StateHnon</th>\n",
       "      <th>State_Holiday_StateHc</th>\n",
       "      <th>State_Holiday_StateHa</th>\n",
       "      <th>State_Holiday_StateHb</th>\n",
       "      <th>School_Holiday_SchoolHoui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249</td>\n",
       "      <td>5</td>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850</td>\n",
       "      <td>3</td>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>776</td>\n",
       "      <td>6</td>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203440</th>\n",
       "      <td>930</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203441</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203442</th>\n",
       "      <td>778</td>\n",
       "      <td>3</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203443</th>\n",
       "      <td>745</td>\n",
       "      <td>6</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203444</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203445 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Day Number_of_Customers  Open_Ooui  Promo_Poui  \\\n",
       "0       249   5                 725          1           1   \n",
       "1       190   4                 564          1           0   \n",
       "2       850   3                 644          1           1   \n",
       "3       776   6                 435          1           0   \n",
       "4        14   4                 799          1           1   \n",
       "...     ...  ..                 ...        ...         ...   \n",
       "203440  930   7                   0          0           0   \n",
       "203441   37   2                 493          1           0   \n",
       "203442  778   3                 791          1           1   \n",
       "203443  745   6                 319          1           0   \n",
       "203444    0   1                   0          0           0   \n",
       "\n",
       "        State_Holiday_StateHnon  State_Holiday_StateHc  State_Holiday_StateHa  \\\n",
       "0                             1                      0                      0   \n",
       "1                             1                      0                      0   \n",
       "2                             1                      0                      0   \n",
       "3                             1                      0                      0   \n",
       "4                             1                      0                      0   \n",
       "...                         ...                    ...                    ...   \n",
       "203440                        1                      0                      0   \n",
       "203441                        1                      0                      0   \n",
       "203442                        1                      0                      0   \n",
       "203443                        1                      0                      0   \n",
       "203444                        1                      0                      0   \n",
       "\n",
       "        State_Holiday_StateHb  School_Holiday_SchoolHoui  \n",
       "0                           0                          0  \n",
       "1                           0                          0  \n",
       "2                           0                          0  \n",
       "3                           0                          0  \n",
       "4                           0                          0  \n",
       "...                       ...                        ...  \n",
       "203440                      0                          0  \n",
       "203441                      0                          0  \n",
       "203442                      0                          0  \n",
       "203443                      0                          0  \n",
       "203444                      0                          0  \n",
       "\n",
       "[203445 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "T_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation du paramètre de complexité du modèle par validation croisée en cherchant l'erreur minimale sur une grille de valeurs du paramètre avec `cv=5`-*fold cross validation* et `n_jobs=-1` pour une exécution en parallèle utilisant tous les processeurs sauf 1. Attention, comme la validation croisée est aléatoire et un arbre un modèle instable, deux exécutions successives ne donnent pas nécessairement le même résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param=[{\"max_depth\":list(range(2,10))}]\n",
    "titan_tree= GridSearchCV(DecisionTreeClassifier(),param,cv=5,n_jobs=-1)\n",
    "titan_opt=titan_tree.fit(T_train, z_train)\n",
    "# paramètre optimal\n",
    "titan_opt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La valeur \"optimale\" du paramètre reste trop importante pour la lisibilité de l'arbre. Une valeur plus faible est utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeClassifier(max_depth=3)\n",
    "titan_tree=tree.fit(T_train, z_train)\n",
    "# Estimation de l'erreur de prévision\n",
    "# sur l'échantillon test\n",
    "1-titan_tree.score(T_test,z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter l'amélioration de l'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prévision de l'échantillon test\n",
    "z_chap = titan_tree.predict(T_test)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(z_test,z_chap)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracer l'arbre avec le logiciel Graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus\n",
    "dot_data = StringIO() \n",
    "export_graphviz(titan_tree, out_file=dot_data) \n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_png(\"titan_tree.png\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'arbre est généré dans un fichier image à visualiser pour se rende compte qu'il est plutôt mal élagué et pas directement interprétable sans les noms en clair des variables et modalités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='titan_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Données   \"Caractères\"\n",
    "La même démarche est utilisée pour ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbre complet\n",
    "tree=DecisionTreeClassifier()\n",
    "digit_tree=tree.fit(X_train, y_train) \n",
    "# Estimation de l'erreur de prévision\n",
    "1-digit_tree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation par validation croisée\n",
    "param=[{\"max_depth\":list(range(5,15))}]\n",
    "digit_tree= GridSearchCV(DecisionTreeClassifier(),param,cv=5,n_jobs=-1)\n",
    "digit_treeOpt=digit_tree.fit(X_train, y_train)\n",
    "digit_treeOpt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation de l'erreur de prévision\n",
    "1-digit_treeOpt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Echantillon test\n",
    "y_chap = digit_treeOpt.predict(X_test)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(y_test,y_chap)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(table)\n",
    "plt.title(\"Matrice de Confusion\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les autres méthodes, l'objet `GridSearchCV` ne contient pas tous les attibuts, dont celui `tree`, et ne permet pas de construire l'arbre. Il faudrait le ré-estimer mais comme il est bien trop complexe, ce résultat n'est pas produit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Forêts aléatoires\n",
    "L'algorithme d'agrégation de modèles le plus utilisé est celui des [forêts aléatoires](http://wikistat.fr/pdf/st-m-app-agreg.pdf) (random forest) de Breiman (2001) ce qui ne signifie pas qu'il conduit toujours à la meilleure prévision. Voir la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) pour la signification de tous les paramètres.\n",
    "\n",
    "Plus que le nombre d'arbres `n_estimators`, le paramètre à optimiser est le nombre de variables tirées aléatoirement pour la recherche de la division optimale d'un noeud: `max_features`. Par défaut, il prend la valeur $\\frac{p}{3}$ en  régression et $\\sqrt{p}$ en discrimination.\n",
    "### 5.1 Données \"Caractères\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# définition des paramètres\n",
    "forest = RandomForestClassifier(n_estimators=500, \n",
    "   criterion='gini', max_depth=None,\n",
    "   min_samples_split=2, min_samples_leaf=1, \n",
    "   max_features='auto', max_leaf_nodes=None,\n",
    "   bootstrap=True, oob_score=True)\n",
    "# apprentissage et erreur out-of-bag\n",
    "forest = forest.fit(X_train,y_train)\n",
    "print(1-forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1-forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimisation du paramètre `max_features` peut être réalisée en minimisant l'erreur de prévision *out-of-bag*. Ce n'est pas prévu, il est aussi possible comme précédemment de minimiser l'erreur par validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param=[{\"max_features\":list(range(4,64,4))}]\n",
    "digit_rf= GridSearchCV(RandomForestClassifier(n_estimators=100),param,cv=5,n_jobs=-1)\n",
    "digit_rfOpt=digit_rf.fit(X_train, y_train)\n",
    "# paramètre optimal\n",
    "digit_rfOpt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les autres méthodes, l'objet `GridSearchCV` ne propose pas tous les attributs et donc pas d'erreur *out-of-bag* ou d'importance des variables. Voir le tutoriel sur la [prévision du pic d'ozone](https://github.com/wikistat/Apprentissage/tree/master/Pic-ozone) pour plus de détails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1-digit_rfOpt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prévision\n",
    "y_chap = digit_rfOpt.predict(X_test)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(y_test,y_chap)\n",
    "print(table)\n",
    "plt.matshow(table)\n",
    "plt.title(\"Matrice de Confusion\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Données \"Titanic\"\n",
    "Même démarche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des paramètres\n",
    "forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, \n",
    "    min_samples_split=2, min_samples_leaf=1, max_features='auto', max_leaf_nodes=None,bootstrap=True, oob_score=True)\n",
    "# apprentissage\n",
    "forest = forest.fit(T_train,z_train)\n",
    "print(1-forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1-forest.score(T_test,z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisation de max_features\n",
    "param=[{\"max_features\":list(range(2,15))}]\n",
    "titan_rf= GridSearchCV(RandomForestClassifier(n_estimators=100),param,cv=5,n_jobs=-1)\n",
    "titan_rfOpt=titan_rf.fit(T_train, z_train)\n",
    "# paramètre optimal\n",
    "titan_rfOpt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1-titan_rfOpt.score(T_test,z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prévision\n",
    "z_chap = titan_rfOpt.predict(T_test)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(z_test,z_chap)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifier la valeur du paramètre pour constater sa faible influence sur la qualité plutôt médiocre du résultat. \n",
    "\n",
    "**Attention**, comme déjà signalé, l'échantillon test est de relativement faible taille (autour de 180), il serait opportun d'itérer l'extraction aléatoire d'échantillons tests (validation croisée *Monte Carlo*)  pour tenter de réduire la variance de cette estimation et avoir une idée de sa distribution.\n",
    "\n",
    "C'est fait dans d'autres calepins du [dépôt d'apprentissage](https://github.com/wikistat/Apprentissage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Fonction *pipeline*\n",
    "Pour enchaîner et brancher (*plugin*) plusieurs traitements, généralement des transformations suivies d'une modélisation. Utiliser les fonctionnalités de cette section sans modération afin d'optimiser la structure et l'efficacité (parallélisation) de codes complexes. \n",
    "\n",
    "### 6.1 Familles de transformations (*transformers*)\n",
    "Classification ou régression sont souvent la dernière étape d'un procédé long et complexe. Dans la \"vraie vie\", les données ont besoin d'être extraites, sélectionnées, nettoyées, standardisées, complétées... (*data munging*) avant d'alimenter un algorithme d'apprentissage. Pour structurer le code, *Sciki-learn* propose d'utiliser le principe d'une API (*application programming interface*) nommée *transformer*. \n",
    "\n",
    "Ces fonctionnalités sont illustrées sur les mêmes données de reconnaissance de caractères. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechargement des données\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Plot\n",
    "sample_id = 42\n",
    "plt.imshow(X[sample_id].reshape((8, 8)), interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"y = %d\" % y[sample_id])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisations, réductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tf = StandardScaler()\n",
    "tf.fit(X_train, y_train)\n",
    "Xt_train = tf.transform(X)  \n",
    "print(\"Moyenne avant centrage et réduction =\", np.mean(X_train))\n",
    "print(\"Moyenne après centrage et réduction =\", np.mean(Xt_train))\n",
    "# See also Binarizer, MinMaxScaler, Normalizer, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raccourci: Xt = tf.fit_transform(X)\n",
    "tf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB. La standardisation préalable est indispensable pour certains algorithmes\n",
    "# notamment les SVM\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "# Calcul des scores (bien classés)\n",
    "print(\"Sans standardisation =\", clf.fit(X_train, y_train).score(X_test, y_test))\n",
    "print(\"Avec standardisation =\", clf.fit(tf.transform(X_train), y_train).score(tf.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection de variables par élimination pas à pas\n",
    "La proicédure `RFE` (*récursive feature selection*) supprime une à une les variables les moins significatives ou moins importantes au sens du critère du modèle utilisé; dans cet exemple, il s'agit des forêts aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection de variables par élémination pas à pas\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tf = RFE(RandomForestClassifier(), n_features_to_select=10, verbose=1)\n",
    "Xt = tf.fit_transform(X_train, y_train)\n",
    "print(\"Shape =\", Xt.shape)\n",
    "\n",
    "# Variables (pixels) sélectionnées\n",
    "plt.imshow(tf.get_support().reshape((8, 8)), interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Décomposition, factorisation, réduction de dimension\n",
    "Possibilité, par exemple, de récupérer les *q* premières composantes principales de l'ACP comme résultat d'une transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par ACP ou SVD\n",
    "from sklearn.decomposition import PCA\n",
    "tf = PCA(n_components=2)\n",
    "Xt_train = tf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fonction  de transformation définie par l'utilisateur\n",
    "Une fonction de transformation ou *transformer* est définie et s'applique à un jeu de données avec la syntaxe ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def increment(X):\n",
    "    return X + 1\n",
    "tf = FunctionTransformer(func=increment)\n",
    "Xt = tf.fit_transform(X)\n",
    "print(X[0])\n",
    "print(Xt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 *Pipelines*\n",
    "\n",
    "Des transformations sont chaînées en une séquence constituant un *pipeline*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "#tf = RFE(RandomForestClassifier(), n_features_to_select=10)\n",
    "# La succession de deux transformeurs constituent un transformeur\n",
    "tf = make_pipeline(StandardScaler(), RFE(RandomForestClassifier(),n_features_to_select=10))\n",
    "tf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_train = tf.transform(X_train)\n",
    "print(\"Mean =\", np.mean(Xt_train))\n",
    "print(\"Shape =\", Xt_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une chaîne de transformations suivi d'un classifieur construisent un nouveau classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), \n",
    "                    RFE(RandomForestClassifier(), n_features_to_select=10), \n",
    "                    RandomForestClassifier())\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.predict_proba(X_test)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'hyperparamètre est accessible\n",
    "print(\"n_features =\", clf.get_params()[\"rfe__estimator__n_estimators\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimisation des paramètres par validation croisée est obtenue avec la même fonction mais peut prendre  du temps si plusieurs paramètres sont cocernés! Le pipeline construit à titre illustratif  n'est certainement pas optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(clf, param_grid={\"rfe__estimator__n_estimators\": [5, 10],\n",
    "                    \"randomforestclassifier__max_features\": [0.1, 0.25, 0.5]})\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Valeurs optimales =\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Union de caractéristiques\n",
    "\n",
    "Des transformations sont appliquées en parallèle pour réunir en un seul ensemble des transformations des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "tf = make_union(PCA(n_components=10), FastICA(n_components=10))\n",
    "Xt_train = tf.fit_transform(X_train)\n",
    "print(\"Shape =\", Xt_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Compositions emboîtées\n",
    "\n",
    "Comme des  pipelines and des unions sont eux-mêmes des estimateurs, ils peuvent être composés dans une structure emboîtée pour construire des combinaisons complexes de modèles comme ceux remportant les concours de type [*kaggle](https://www.kaggle.com/).\n",
    "\n",
    "Les données initiales sont unies aux composantes de l'ACP, puis les variables les plus importantes au sens des forêts aléatoires sont sélectionnées avant de servir à l'apprentissage d'un réseau de neurones. Ce n'est sûrement pas une stratégie optimale !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = make_pipeline(\n",
    "    # Build features\n",
    "    make_union(\n",
    "        FunctionTransformer(func=lambda X: X), PCA(),), \n",
    "    # Select the best features\n",
    "    RFE(RandomForestClassifier(), n_features_to_select=10),\n",
    "    # Train\n",
    "    MLPClassifier(max_iter=500)\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectivement la combinaison n'est pas optimale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de test\n",
    "1-clf.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
